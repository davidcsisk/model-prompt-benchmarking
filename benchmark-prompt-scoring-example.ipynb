{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "201307bf",
   "metadata": {},
   "source": [
    "## Benchmark Prompt Scoring Example\n",
    "6/12/2025, Dave Sisk, https://github.com/davidcsisk, https://www.linkedin.com/in/davesisk-doctordatabase/\n",
    "\n",
    "#### Scoring Approaches\n",
    "\n",
    "The following scoring approaches are used to evaluate the similarity between prompts and responses:\n",
    "\n",
    "1. **Cosine Similarity**:\n",
    "   - **Description**: Measures the cosine of the angle between two vectors in an embedding space. It evaluates the semantic similarity between the prompt and response.\n",
    "   - **Range**: 0 to 1\n",
    "   - **Better Score**: Higher scores indicate greater similarity.\n",
    "\n",
    "2. **BERTScore (F1)**:\n",
    "   - **Description**: Uses contextual embeddings from BERT to compute precision, recall, and F1 scores for text similarity. The F1 score is used here.\n",
    "   - **Range**: 0 to 1\n",
    "   - **Better Score**: Higher scores indicate better alignment between the prompt and response.\n",
    "\n",
    "3. **ROUGE-L**:\n",
    "   - **Description**: Measures the longest common subsequence (LCS) between the prompt and response. It is commonly used for evaluating text summarization.\n",
    "   - **Range**: 0 to 1\n",
    "   - **Better Score**: Higher scores indicate better overlap between the prompt and response.\n",
    "\n",
    "4. **BLEU**:\n",
    "   - **Description**: Evaluates the n-gram overlap between the prompt and response. It is commonly used for machine translation tasks.\n",
    "   - **Range**: 0 to 1\n",
    "   - **Better Score**: Higher scores indicate better n-gram overlap.\n",
    "\n",
    "Each of these metrics provides a unique perspective on the quality of the response, with higher scores generally indicating better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ca3f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (safe to re-run)\n",
    "#!pip install pandas sentence-transformers bert_score nltk rouge-score --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc4a1881",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dave Sisk\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from bert_score import score as bert_score\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from rouge_score import rouge_scorer\n",
    "from IPython.display import display\n",
    "from pathlib import Path\n",
    "\n",
    "# Download NLTK resources\n",
    "import nltk\n",
    "nltk.download('punkt', quiet=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc8cac9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring in progress...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Scores written to: benchmark-prompt-scoring_chatgpt-test_scored.csv\n"
     ]
    }
   ],
   "source": [
    "# Score the responses in a variety of ways into a new CSV file \n",
    "def process_file(file_path):\n",
    "#    \"\"\"Process file and save scores without any UI interaction\"\"\"\n",
    "    # Load file\n",
    "    df = pd.read_csv(file_path)\n",
    "    assert \"Prompt\" in df.columns and \"Response\" in df.columns, \"❌ CSV must contain 'Prompt' and 'Response' columns\"\n",
    "\n",
    "    # Load models\n",
    "    embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "    rouge = rouge_scorer.RougeScorer([\"rougeL\"], use_stemmer=True)\n",
    "    smooth = SmoothingFunction()\n",
    "\n",
    "    cosine_scores = []\n",
    "    bert_f1_scores = []\n",
    "    rouge_l_scores = []\n",
    "    bleu_scores = []\n",
    "\n",
    "    print(\"Scoring in progress...\")\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        prompt, response = row[\"Prompt\"], row[\"Response\"]\n",
    "\n",
    "        # Cosine similarity (embeddings)\n",
    "        try:\n",
    "            p_vec = embed_model.encode(prompt, convert_to_tensor=True)\n",
    "            r_vec = embed_model.encode(response, convert_to_tensor=True)\n",
    "            cosine = util.pytorch_cos_sim(p_vec, r_vec).item()\n",
    "        except:\n",
    "            cosine = 0.0\n",
    "\n",
    "        # BERTScore\n",
    "        try:\n",
    "            _, _, F1 = bert_score([response], [prompt], lang=\"en\", verbose=False)\n",
    "            bert_f1 = F1[0].item()\n",
    "        except:\n",
    "            bert_f1 = 0.0\n",
    "\n",
    "        # ROUGE-L\n",
    "        try:\n",
    "            rouge_l = rouge.score(prompt, response)[\"rougeL\"].fmeasure\n",
    "        except:\n",
    "            rouge_l = 0.0\n",
    "\n",
    "        # BLEU\n",
    "        try:\n",
    "            prompt_tokens = nltk.word_tokenize(prompt)\n",
    "            response_tokens = nltk.word_tokenize(response)\n",
    "            bleu = sentence_bleu([prompt_tokens], response_tokens, smoothing_function=smooth.method1)\n",
    "        except:\n",
    "            bleu = 0.0\n",
    "\n",
    "        cosine_scores.append(cosine)\n",
    "        bert_f1_scores.append(bert_f1)\n",
    "        rouge_l_scores.append(rouge_l)\n",
    "        bleu_scores.append(bleu)\n",
    "\n",
    "    df[\"CosineSimilarity\"] = cosine_scores\n",
    "    df[\"BERTScore_F1\"] = bert_f1_scores\n",
    "    df[\"ROUGE_L\"] = rouge_l_scores\n",
    "    df[\"BLEU\"] = bleu_scores\n",
    "\n",
    "    # Save results to file\n",
    "    output_file = Path(file_path).stem + \"_scored.csv\"\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"✅ Scores written to: {output_file}\")\n",
    "\n",
    "# Example usage (uncomment to run):\n",
    "process_file(\"benchmark-prompt-scoring_chatgpt-test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffdabf0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prompt</th>\n",
       "      <th>CosineSimilarity</th>\n",
       "      <th>BERTScore_F1</th>\n",
       "      <th>ROUGE_L</th>\n",
       "      <th>BLEU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Write a Python script to process log files and identify anomalies based on time gaps (Prompt 1).</td>\n",
       "      <td>0.875589</td>\n",
       "      <td>0.801565</td>\n",
       "      <td>0.107692</td>\n",
       "      <td>0.021988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Create an SPL query to detect potential data exfiltration via large outbound transfers (Prompt 2).</td>\n",
       "      <td>0.267022</td>\n",
       "      <td>0.787284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Write a SQL query to retrieve the top 5 users with the most failed logins in the past 24 hours (Prompt 3).</td>\n",
       "      <td>0.809982</td>\n",
       "      <td>0.843360</td>\n",
       "      <td>0.206349</td>\n",
       "      <td>0.061723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Use Python to call the Splunk REST API, execute a search, and visualize login attempts per hour (Prompt 4).</td>\n",
       "      <td>0.812615</td>\n",
       "      <td>0.809521</td>\n",
       "      <td>0.057495</td>\n",
       "      <td>0.015800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Write a Python script that connects to a PostgreSQL database, inserts network event logs, and runs a summary query (Prompt 5).</td>\n",
       "      <td>0.736720</td>\n",
       "      <td>0.797282</td>\n",
       "      <td>0.119205</td>\n",
       "      <td>0.049994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Write a Python script to process log files and identify anomalies based on time gaps (Prompt 6).</td>\n",
       "      <td>0.873184</td>\n",
       "      <td>0.792551</td>\n",
       "      <td>0.087248</td>\n",
       "      <td>0.012537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Create an SPL query to detect potential data exfiltration via large outbound transfers (Prompt 7).</td>\n",
       "      <td>0.291735</td>\n",
       "      <td>0.794012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Write a SQL query to retrieve the top 5 users with the most failed logins in the past 24 hours (Prompt 8).</td>\n",
       "      <td>0.800837</td>\n",
       "      <td>0.843803</td>\n",
       "      <td>0.206349</td>\n",
       "      <td>0.057440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Use Python to call the Splunk REST API, execute a search, and visualize login attempts per hour (Prompt 9).</td>\n",
       "      <td>0.808533</td>\n",
       "      <td>0.812193</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.018860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Write a Python script that connects to a PostgreSQL database, inserts network event logs, and runs a summary query (Prompt 10).</td>\n",
       "      <td>0.788432</td>\n",
       "      <td>0.796967</td>\n",
       "      <td>0.138996</td>\n",
       "      <td>0.053330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Explain the difference between symmetric and asymmetric encryption with examples. (Benchmark 1)</td>\n",
       "      <td>0.720957</td>\n",
       "      <td>0.827540</td>\n",
       "      <td>0.046980</td>\n",
       "      <td>0.015687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Summarize the MITRE ATT&amp;CK framework and its primary use cases in threat detection. (Benchmark 2)</td>\n",
       "      <td>0.777159</td>\n",
       "      <td>0.834560</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.023898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>What are the key stages in a typical ransomware attack lifecycle? (Benchmark 3)</td>\n",
       "      <td>0.620825</td>\n",
       "      <td>0.821772</td>\n",
       "      <td>0.044776</td>\n",
       "      <td>0.002063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>How does DNS tunneling work and how can it be detected? (Benchmark 4)</td>\n",
       "      <td>0.769107</td>\n",
       "      <td>0.814129</td>\n",
       "      <td>0.046620</td>\n",
       "      <td>0.001152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Compare the advantages and limitations of signature-based vs behavior-based detection. (Benchmark 5)</td>\n",
       "      <td>0.700556</td>\n",
       "      <td>0.825845</td>\n",
       "      <td>0.064103</td>\n",
       "      <td>0.000813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>What are zero-day vulnerabilities, and how are they typically exploited in the wild? (Benchmark 6)</td>\n",
       "      <td>0.796424</td>\n",
       "      <td>0.835153</td>\n",
       "      <td>0.078740</td>\n",
       "      <td>0.003245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Explain how an intrusion detection system (IDS) works and give examples of open-source IDS platforms. (Benchmark 7)</td>\n",
       "      <td>0.656538</td>\n",
       "      <td>0.824995</td>\n",
       "      <td>0.065990</td>\n",
       "      <td>0.014057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Describe how adversarial machine learning can be used to evade anomaly detection models. (Benchmark 8)</td>\n",
       "      <td>0.734021</td>\n",
       "      <td>0.839137</td>\n",
       "      <td>0.078014</td>\n",
       "      <td>0.025551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>What role does entropy analysis play in malware detection? (Benchmark 9)</td>\n",
       "      <td>0.796724</td>\n",
       "      <td>0.849283</td>\n",
       "      <td>0.092593</td>\n",
       "      <td>0.010693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>How can organizations protect against supply chain attacks like the SolarWinds breach? (Benchmark 10)</td>\n",
       "      <td>0.641081</td>\n",
       "      <td>0.814466</td>\n",
       "      <td>0.039773</td>\n",
       "      <td>0.000809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                             Prompt  \\\n",
       "0                                  Write a Python script to process log files and identify anomalies based on time gaps (Prompt 1).   \n",
       "1                                Create an SPL query to detect potential data exfiltration via large outbound transfers (Prompt 2).   \n",
       "2                        Write a SQL query to retrieve the top 5 users with the most failed logins in the past 24 hours (Prompt 3).   \n",
       "3                       Use Python to call the Splunk REST API, execute a search, and visualize login attempts per hour (Prompt 4).   \n",
       "4    Write a Python script that connects to a PostgreSQL database, inserts network event logs, and runs a summary query (Prompt 5).   \n",
       "5                                  Write a Python script to process log files and identify anomalies based on time gaps (Prompt 6).   \n",
       "6                                Create an SPL query to detect potential data exfiltration via large outbound transfers (Prompt 7).   \n",
       "7                        Write a SQL query to retrieve the top 5 users with the most failed logins in the past 24 hours (Prompt 8).   \n",
       "8                       Use Python to call the Splunk REST API, execute a search, and visualize login attempts per hour (Prompt 9).   \n",
       "9   Write a Python script that connects to a PostgreSQL database, inserts network event logs, and runs a summary query (Prompt 10).   \n",
       "10                                  Explain the difference between symmetric and asymmetric encryption with examples. (Benchmark 1)   \n",
       "11                                Summarize the MITRE ATT&CK framework and its primary use cases in threat detection. (Benchmark 2)   \n",
       "12                                                  What are the key stages in a typical ransomware attack lifecycle? (Benchmark 3)   \n",
       "13                                                            How does DNS tunneling work and how can it be detected? (Benchmark 4)   \n",
       "14                             Compare the advantages and limitations of signature-based vs behavior-based detection. (Benchmark 5)   \n",
       "15                               What are zero-day vulnerabilities, and how are they typically exploited in the wild? (Benchmark 6)   \n",
       "16              Explain how an intrusion detection system (IDS) works and give examples of open-source IDS platforms. (Benchmark 7)   \n",
       "17                           Describe how adversarial machine learning can be used to evade anomaly detection models. (Benchmark 8)   \n",
       "18                                                         What role does entropy analysis play in malware detection? (Benchmark 9)   \n",
       "19                            How can organizations protect against supply chain attacks like the SolarWinds breach? (Benchmark 10)   \n",
       "\n",
       "    CosineSimilarity  BERTScore_F1   ROUGE_L      BLEU  \n",
       "0           0.875589      0.801565  0.107692  0.021988  \n",
       "1           0.267022      0.787284  0.000000  0.007426  \n",
       "2           0.809982      0.843360  0.206349  0.061723  \n",
       "3           0.812615      0.809521  0.057495  0.015800  \n",
       "4           0.736720      0.797282  0.119205  0.049994  \n",
       "5           0.873184      0.792551  0.087248  0.012537  \n",
       "6           0.291735      0.794012  0.000000  0.009849  \n",
       "7           0.800837      0.843803  0.206349  0.057440  \n",
       "8           0.808533      0.812193  0.071429  0.018860  \n",
       "9           0.788432      0.796967  0.138996  0.053330  \n",
       "10          0.720957      0.827540  0.046980  0.015687  \n",
       "11          0.777159      0.834560  0.090909  0.023898  \n",
       "12          0.620825      0.821772  0.044776  0.002063  \n",
       "13          0.769107      0.814129  0.046620  0.001152  \n",
       "14          0.700556      0.825845  0.064103  0.000813  \n",
       "15          0.796424      0.835153  0.078740  0.003245  \n",
       "16          0.656538      0.824995  0.065990  0.014057  \n",
       "17          0.734021      0.839137  0.078014  0.025551  \n",
       "18          0.796724      0.849283  0.092593  0.010693  \n",
       "19          0.641081      0.814466  0.039773  0.000809  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the scored CSV and display selected columns in a nice table\n",
    "scored_df = pd.read_csv(\"benchmark-prompt-scoring_chatgpt-test_scored.csv\")\n",
    "\n",
    "# Ensure the full content of the Prompt column is displayed\n",
    "pd.set_option('display.max_colwidth', None)  # Show full content of text columns\n",
    "pd.set_option('display.max_rows', None)      # Show all rows if needed\n",
    "\n",
    "display(scored_df[[\"Prompt\", \"CosineSimilarity\", \"BERTScore_F1\", \"ROUGE_L\", \"BLEU\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e245dd2",
   "metadata": {},
   "source": [
    "Open the scored CSV file note above with a suitable spreadsheet program or CSV viewer/editor to examine the prompts, responses, and scores in more detail. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
